version: 3.1.0

pipeline:
  name: pyannote.audio.pipelines.SpeakerDiarization
  params:
    clustering: AgglomerativeClustering
    embedding: /Users/jf3375/PycharmProjects/SpeechMLPipeline/models/Pyannote3.1/Embedding/pytorch_model.bin
    embedding_batch_size: 32
    embedding_exclude_overlap: true
    segmentation: //Users/jf3375/PycharmProjects/SpeechMLPipeline/models/Pyannote3.1/Segmentation/pytorch_model.bin
    segmentation_batch_size: 32

params:
  clustering:
    method: centroid
    min_cluster_size: 12
    threshold: 0.7045654963945799
  segmentation:
    min_duration_off: 0.0
